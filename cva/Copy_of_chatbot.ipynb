{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5iNIkcKzpWgc"
      },
      "outputs": [],
      "source": [
        "#import necessary libraries\n",
        "import numpy as np\n",
        "import json\n",
        "import random\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Nwo3zFiVpme5"
      },
      "outputs": [],
      "source": [
        "# Load the intents from the JSON file\n",
        "with open('C:\\\\Users\\\\Dishant\\\\Desktop\\\\Mlsccoherence_teamRadhey\\\\cva\\\\intents.json', 'r') as file:\n",
        "    intents = json.load(file)['intents']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkP8ISE2kMqW",
        "outputId": "f4dbb89a-676d-4c9a-cb77-11da4a397593"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzsUbT1Hv4iv"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87hjt6vIjuV-",
        "outputId": "2a4923fc-5549-41fd-b6cc-a35e54536c3e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Dishant\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\Dishant\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RY95-aw3pqPb"
      },
      "outputs": [],
      "source": [
        "# Initialize the lemmatizer and tokenizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "tokenizer = word_tokenize\n",
        "# Create a list of all words in the intents, and a list of all intents\n",
        "words = []\n",
        "classes = []\n",
        "documents = []\n",
        "for intent in intents:\n",
        "    for pattern in intent['patterns']:\n",
        "        # Tokenize and lemmatize each word in the pattern\n",
        "        words_in_pattern = tokenizer(pattern.lower())\n",
        "        words_in_pattern = [lemmatizer.lemmatize(word) for word in words_in_pattern]\n",
        "        # Add the words to the list of all words\n",
        "        words.extend(words_in_pattern)\n",
        "        # Add the pattern and intent to the list of all documents\n",
        "        documents.append((words_in_pattern, intent['tag']))\n",
        "        # Add the intent to the list of all intents\n",
        "        if intent['tag'] not in classes:\n",
        "            classes.append(intent['tag'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eAhXZ4c3ptXN"
      },
      "outputs": [],
      "source": [
        "# Remove duplicates and sort the words and classes\n",
        "words = sorted(list(set(words)))\n",
        "classes = sorted(classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "a_eIAhQ5pvbC"
      },
      "outputs": [],
      "source": [
        "# Create training data as a bag of words\n",
        "training_data = []\n",
        "for document in documents:\n",
        "    bag = []\n",
        "    # Create a bag of words for each document\n",
        "    for word in words:\n",
        "        bag.append(1) if word in document[0] else bag.append(0)\n",
        "    # Append the bag of words and the intent tag to the training data\n",
        "    output_row = [0] * len(classes)\n",
        "    output_row[classes.index(document[1])] = 1\n",
        "    training_data.append([bag, output_row])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iRgiwTO-p1GK"
      },
      "outputs": [],
      "source": [
        "# Shuffle the training data and split it into input and output lists\n",
        "random.shuffle(training_data)\n",
        "training_data = np.array(training_data, dtype=object)\n",
        "train_x = list(training_data[:, 0])\n",
        "train_y = list(training_data[:, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "BfMnDZTIp215"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Dishant\\Desktop\\Mlsccoherence_teamRadhey\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Define the neural network model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, input_shape=(len(train_x[0]),), activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(len(train_y[0]), activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_s3CSYivp6lt",
        "outputId": "f47b0576-61c1-423d-ecfb-c606da05342e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0521 - loss: 3.7379  \n",
            "Epoch 2/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0769 - loss: 3.6428\n",
            "Epoch 3/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0476 - loss: 3.5862   \n",
            "Epoch 4/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0576 - loss: 3.5515   \n",
            "Epoch 5/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0602 - loss: 3.4981   \n",
            "Epoch 6/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1245 - loss: 3.4604   \n",
            "Epoch 7/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1401 - loss: 3.3383\n",
            "Epoch 8/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1508 - loss: 3.2152\n",
            "Epoch 9/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2555 - loss: 3.0822\n",
            "Epoch 10/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2398 - loss: 3.0709\n",
            "Epoch 11/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3293 - loss: 2.8686\n",
            "Epoch 12/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3673 - loss: 2.7140\n",
            "Epoch 13/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3653 - loss: 2.4786\n",
            "Epoch 14/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4317 - loss: 2.3524\n",
            "Epoch 15/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4005 - loss: 2.5526\n",
            "Epoch 16/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4012 - loss: 2.2256\n",
            "Epoch 17/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3809 - loss: 2.2807\n",
            "Epoch 18/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5204 - loss: 1.9968\n",
            "Epoch 19/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3885 - loss: 2.2640\n",
            "Epoch 20/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5322 - loss: 1.7791\n",
            "Epoch 21/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4969 - loss: 1.9402\n",
            "Epoch 22/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6145 - loss: 1.6206\n",
            "Epoch 23/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5556 - loss: 1.7510\n",
            "Epoch 24/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6714 - loss: 1.4732\n",
            "Epoch 25/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7534 - loss: 1.3773\n",
            "Epoch 26/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7295 - loss: 1.3669\n",
            "Epoch 27/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6685 - loss: 1.3504\n",
            "Epoch 28/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7273 - loss: 1.3074\n",
            "Epoch 29/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7941 - loss: 1.0787\n",
            "Epoch 30/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6512 - loss: 1.2199\n",
            "Epoch 31/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8013 - loss: 1.1131\n",
            "Epoch 32/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7749 - loss: 1.1800\n",
            "Epoch 33/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7888 - loss: 1.1068\n",
            "Epoch 34/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6554 - loss: 1.1597\n",
            "Epoch 35/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8220 - loss: 1.0111\n",
            "Epoch 36/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7561 - loss: 0.9792\n",
            "Epoch 37/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7440 - loss: 0.9845\n",
            "Epoch 38/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8626 - loss: 0.7740\n",
            "Epoch 39/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7798 - loss: 0.8292\n",
            "Epoch 40/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8698 - loss: 0.8188\n",
            "Epoch 41/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7746 - loss: 0.8515\n",
            "Epoch 42/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7966 - loss: 0.8935\n",
            "Epoch 43/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8034 - loss: 0.7026\n",
            "Epoch 44/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8307 - loss: 0.6937\n",
            "Epoch 45/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8370 - loss: 0.6658\n",
            "Epoch 46/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8355 - loss: 0.6297\n",
            "Epoch 47/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8703 - loss: 0.7027\n",
            "Epoch 48/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8010 - loss: 0.6048\n",
            "Epoch 49/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8652 - loss: 0.5861\n",
            "Epoch 50/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8690 - loss: 0.5128\n",
            "Epoch 51/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8009 - loss: 0.7045\n",
            "Epoch 52/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7654 - loss: 0.6812\n",
            "Epoch 53/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8507 - loss: 0.6885\n",
            "Epoch 54/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8292 - loss: 0.5880\n",
            "Epoch 55/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8853 - loss: 0.4923\n",
            "Epoch 56/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8637 - loss: 0.5314\n",
            "Epoch 57/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9377 - loss: 0.4591\n",
            "Epoch 58/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8166 - loss: 0.5971\n",
            "Epoch 59/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8782 - loss: 0.5865\n",
            "Epoch 60/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8929 - loss: 0.5457\n",
            "Epoch 61/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8317 - loss: 0.5299\n",
            "Epoch 62/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8991 - loss: 0.5227\n",
            "Epoch 63/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9067 - loss: 0.4207\n",
            "Epoch 64/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9477 - loss: 0.4081\n",
            "Epoch 65/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8478 - loss: 0.4788\n",
            "Epoch 66/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8777 - loss: 0.4186\n",
            "Epoch 67/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8807 - loss: 0.3951\n",
            "Epoch 68/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8625 - loss: 0.5274\n",
            "Epoch 69/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9021 - loss: 0.4320\n",
            "Epoch 70/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8502 - loss: 0.5316\n",
            "Epoch 71/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8547 - loss: 0.5075\n",
            "Epoch 72/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8518 - loss: 0.4102\n",
            "Epoch 73/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8902 - loss: 0.4529\n",
            "Epoch 74/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8879 - loss: 0.4475\n",
            "Epoch 75/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9003 - loss: 0.3879\n",
            "Epoch 76/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8824 - loss: 0.4658\n",
            "Epoch 77/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8619 - loss: 0.5026\n",
            "Epoch 78/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.3518\n",
            "Epoch 79/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.3925\n",
            "Epoch 80/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9209 - loss: 0.2824\n",
            "Epoch 81/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9171 - loss: 0.3271\n",
            "Epoch 82/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9766 - loss: 0.1863\n",
            "Epoch 83/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9526 - loss: 0.2701\n",
            "Epoch 84/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9672 - loss: 0.2531\n",
            "Epoch 85/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8837 - loss: 0.3560\n",
            "Epoch 86/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8940 - loss: 0.3311\n",
            "Epoch 87/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8624 - loss: 0.3756\n",
            "Epoch 88/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9331 - loss: 0.2697\n",
            "Epoch 89/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9418 - loss: 0.2284\n",
            "Epoch 90/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9399 - loss: 0.3093\n",
            "Epoch 91/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9421 - loss: 0.2717\n",
            "Epoch 92/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8489 - loss: 0.5421\n",
            "Epoch 93/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9297 - loss: 0.2760\n",
            "Epoch 94/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9185 - loss: 0.3164\n",
            "Epoch 95/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9653 - loss: 0.2911\n",
            "Epoch 96/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9635 - loss: 0.2046\n",
            "Epoch 97/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8986 - loss: 0.3359\n",
            "Epoch 98/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8970 - loss: 0.3836\n",
            "Epoch 99/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8420 - loss: 0.3824\n",
            "Epoch 100/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9426 - loss: 0.2147\n",
            "Epoch 101/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9569 - loss: 0.2171\n",
            "Epoch 102/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.2589\n",
            "Epoch 103/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9845 - loss: 0.1750\n",
            "Epoch 104/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9560 - loss: 0.1908\n",
            "Epoch 105/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9360 - loss: 0.2496\n",
            "Epoch 106/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9373 - loss: 0.1675\n",
            "Epoch 107/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9652 - loss: 0.1899\n",
            "Epoch 108/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9620 - loss: 0.2430\n",
            "Epoch 109/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9501 - loss: 0.1887\n",
            "Epoch 110/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9276 - loss: 0.2305\n",
            "Epoch 111/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9274 - loss: 0.3002\n",
            "Epoch 112/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9187 - loss: 0.2113\n",
            "Epoch 113/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8784 - loss: 0.3909\n",
            "Epoch 114/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9425 - loss: 0.1816\n",
            "Epoch 115/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9267 - loss: 0.2455\n",
            "Epoch 116/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9558 - loss: 0.1810\n",
            "Epoch 117/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9047 - loss: 0.2350\n",
            "Epoch 118/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9348 - loss: 0.2178\n",
            "Epoch 119/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2875\n",
            "Epoch 120/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9299 - loss: 0.3547\n",
            "Epoch 121/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8875 - loss: 0.2831\n",
            "Epoch 122/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2194\n",
            "Epoch 123/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9473 - loss: 0.1617\n",
            "Epoch 124/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9576 - loss: 0.1461\n",
            "Epoch 125/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9445 - loss: 0.1954\n",
            "Epoch 126/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9576 - loss: 0.1906\n",
            "Epoch 127/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9271 - loss: 0.2253\n",
            "Epoch 128/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9044 - loss: 0.2092\n",
            "Epoch 129/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9331 - loss: 0.1638\n",
            "Epoch 130/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8834 - loss: 0.2427\n",
            "Epoch 131/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9616 - loss: 0.1726\n",
            "Epoch 132/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9214 - loss: 0.2375\n",
            "Epoch 133/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9783 - loss: 0.1312\n",
            "Epoch 134/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9456 - loss: 0.1424\n",
            "Epoch 135/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9613 - loss: 0.1732\n",
            "Epoch 136/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8938 - loss: 0.2186\n",
            "Epoch 137/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9291 - loss: 0.2157\n",
            "Epoch 138/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9423 - loss: 0.2860\n",
            "Epoch 139/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9544 - loss: 0.1389\n",
            "Epoch 140/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9431 - loss: 0.1769   \n",
            "Epoch 141/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9747 - loss: 0.0869\n",
            "Epoch 142/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9705 - loss: 0.0988\n",
            "Epoch 143/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9835 - loss: 0.1220\n",
            "Epoch 144/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9417 - loss: 0.1668\n",
            "Epoch 145/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8522 - loss: 0.4363\n",
            "Epoch 146/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9043 - loss: 0.2022\n",
            "Epoch 147/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9560 - loss: 0.1620\n",
            "Epoch 148/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9671 - loss: 0.1309\n",
            "Epoch 149/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9194 - loss: 0.1851\n",
            "Epoch 150/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9527 - loss: 0.1471\n",
            "Epoch 151/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9698 - loss: 0.0990\n",
            "Epoch 152/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9737 - loss: 0.1219\n",
            "Epoch 153/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9574 - loss: 0.1445\n",
            "Epoch 154/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9284 - loss: 0.2704\n",
            "Epoch 155/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9530 - loss: 0.1575\n",
            "Epoch 156/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9821 - loss: 0.1273\n",
            "Epoch 157/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9783 - loss: 0.1186\n",
            "Epoch 158/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9439 - loss: 0.1940\n",
            "Epoch 159/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9615 - loss: 0.1328\n",
            "Epoch 160/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9383 - loss: 0.1815\n",
            "Epoch 161/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9423 - loss: 0.1683\n",
            "Epoch 162/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9746 - loss: 0.1004\n",
            "Epoch 163/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9811 - loss: 0.0867\n",
            "Epoch 164/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9921 - loss: 0.1202\n",
            "Epoch 165/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9620 - loss: 0.1844\n",
            "Epoch 166/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9441 - loss: 0.1485\n",
            "Epoch 167/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9770 - loss: 0.1440\n",
            "Epoch 168/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9075 - loss: 0.2583\n",
            "Epoch 169/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9639 - loss: 0.1081\n",
            "Epoch 170/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8795 - loss: 0.3598\n",
            "Epoch 171/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9244 - loss: 0.1499\n",
            "Epoch 172/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9214 - loss: 0.2320\n",
            "Epoch 173/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9599 - loss: 0.1441\n",
            "Epoch 174/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9210 - loss: 0.1600\n",
            "Epoch 175/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9801 - loss: 0.0977\n",
            "Epoch 176/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9591 - loss: 0.1677\n",
            "Epoch 177/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9657 - loss: 0.1445\n",
            "Epoch 178/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9653 - loss: 0.0949\n",
            "Epoch 179/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.1393\n",
            "Epoch 180/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9793 - loss: 0.0813\n",
            "Epoch 181/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9167 - loss: 0.2445\n",
            "Epoch 182/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9645 - loss: 0.1088\n",
            "Epoch 183/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9648 - loss: 0.1856\n",
            "Epoch 184/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9244 - loss: 0.1677\n",
            "Epoch 185/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9742 - loss: 0.1090   \n",
            "Epoch 186/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9732 - loss: 0.1188\n",
            "Epoch 187/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9595 - loss: 0.2039\n",
            "Epoch 188/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9592 - loss: 0.1193\n",
            "Epoch 189/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9656 - loss: 0.1544\n",
            "Epoch 190/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9588 - loss: 0.1482\n",
            "Epoch 191/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9657 - loss: 0.1490\n",
            "Epoch 192/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9671 - loss: 0.1287\n",
            "Epoch 193/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9690 - loss: 0.1089\n",
            "Epoch 194/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9433 - loss: 0.1461\n",
            "Epoch 195/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9781 - loss: 0.0919\n",
            "Epoch 196/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9962 - loss: 0.0904\n",
            "Epoch 197/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9382 - loss: 0.1956\n",
            "Epoch 198/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9845 - loss: 0.0654\n",
            "Epoch 199/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9419 - loss: 0.1647\n",
            "Epoch 200/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9503 - loss: 0.1257\n",
            "Epoch 201/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9674 - loss: 0.1362\n",
            "Epoch 202/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9939 - loss: 0.0617\n",
            "Epoch 203/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9570 - loss: 0.1770\n",
            "Epoch 204/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9695 - loss: 0.1253\n",
            "Epoch 205/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9626 - loss: 0.1170\n",
            "Epoch 206/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9420 - loss: 0.1722\n",
            "Epoch 207/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9839 - loss: 0.0616   \n",
            "Epoch 208/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9451 - loss: 0.1548\n",
            "Epoch 209/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9313 - loss: 0.1503\n",
            "Epoch 210/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9441 - loss: 0.1344\n",
            "Epoch 211/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9634 - loss: 0.1188\n",
            "Epoch 212/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0420   \n",
            "Epoch 213/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9858 - loss: 0.1020\n",
            "Epoch 214/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9521 - loss: 0.1670\n",
            "Epoch 215/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9185 - loss: 0.1775\n",
            "Epoch 216/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9345 - loss: 0.1669\n",
            "Epoch 217/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9267 - loss: 0.2037\n",
            "Epoch 218/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9523 - loss: 0.1039\n",
            "Epoch 219/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9721 - loss: 0.1233\n",
            "Epoch 220/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9348 - loss: 0.2201\n",
            "Epoch 221/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9364 - loss: 0.1928\n",
            "Epoch 222/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9761 - loss: 0.0702\n",
            "Epoch 223/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9513 - loss: 0.2037\n",
            "Epoch 224/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9446 - loss: 0.1281\n",
            "Epoch 225/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9431 - loss: 0.1453   \n",
            "Epoch 226/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9625 - loss: 0.1392\n",
            "Epoch 227/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9618 - loss: 0.1420\n",
            "Epoch 228/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9724 - loss: 0.1156\n",
            "Epoch 229/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9458 - loss: 0.1847\n",
            "Epoch 230/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9955 - loss: 0.0400\n",
            "Epoch 231/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9688 - loss: 0.1174\n",
            "Epoch 232/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9700 - loss: 0.0929\n",
            "Epoch 233/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9285 - loss: 0.1464\n",
            "Epoch 234/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9966 - loss: 0.0441\n",
            "Epoch 235/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9553 - loss: 0.1168\n",
            "Epoch 236/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9851 - loss: 0.1427\n",
            "Epoch 237/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9011 - loss: 0.1769\n",
            "Epoch 238/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9722 - loss: 0.0821\n",
            "Epoch 239/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9542 - loss: 0.0925\n",
            "Epoch 240/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9457 - loss: 0.2025\n",
            "Epoch 241/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.1005\n",
            "Epoch 242/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9841 - loss: 0.0650\n",
            "Epoch 243/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9456 - loss: 0.1308\n",
            "Epoch 244/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9690 - loss: 0.1071\n",
            "Epoch 245/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9578 - loss: 0.1437\n",
            "Epoch 246/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9571 - loss: 0.1951\n",
            "Epoch 247/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0555\n",
            "Epoch 248/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9440 - loss: 0.1148\n",
            "Epoch 249/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9603 - loss: 0.1231\n",
            "Epoch 250/250\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9501 - loss: 0.1566\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x26f2eec05d0>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(np.array(train_x), np.array(train_y), epochs=250, batch_size=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hghjs5hvp-2H",
        "outputId": "e622f1e9-d236-4aa1-fd1f-2ad8bba875e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "greeting\n",
            "CVA :: Hey! What do you need help with?\n",
            "greetreply\n",
            "CVA :: Good to know!\n",
            "help\n",
            "CVA :: Yes Sure, How can I support you\n",
            "cancel_order\n",
            "CVA :: We apologize for any inconvenience. Please provide your order number and we will cancel your order for you.\n",
            "cancel_order\n",
            "CVA :: Of course, we can cancel your order. Please provide your order number and we will take care of it.\n",
            "noanswer\n",
            "CVA :: Please give me more info\n",
            "oder_number\n",
            "CVA :: Thank you for providing the order number. Let me check the status of your order.\n",
            "noanswer\n",
            "CVA :: Not sure I understand\n",
            "noanswer\n",
            "CVA :: Please give me more info\n",
            "noanswer\n",
            "CVA :: Please give me more info\n",
            "noanswer\n",
            "CVA :: Sorry, can't understand you\n",
            "noanswer\n",
            "CVA :: Sorry, can't understand you\n",
            "noanswer\n",
            "CVA :: Please give me more info\n",
            "noanswer\n",
            "CVA :: Sorry, can't understand you\n",
            "noanswer\n",
            "CVA :: Please give me more info\n",
            "noanswer\n",
            "CVA :: Please give me more info\n",
            "noanswer\n",
            "CVA :: Sorry, can't understand you\n"
          ]
        }
      ],
      "source": [
        "# Define a function to process user input and generate a response\n",
        "def get_response(user_input):\n",
        "    # Tokenize and lemmatize the user input\n",
        "    words_in_input = tokenizer(user_input.lower())\n",
        "    words_in_input = [lemmatizer.lemmatize(word) for word in words_in_input]\n",
        "\n",
        "    # Create a bag of words for the user input\n",
        "    bag = [0] * len(words)\n",
        "    for word in words_in_input:\n",
        "        for i, w in enumerate(words):\n",
        "            if w == word:\n",
        "                bag[i] = 1\n",
        "\n",
        "    # Predict the intent of the user input using the trained model\n",
        "    results = model.predict(np.array([bag]), verbose=0)[0]\n",
        "    # Get the index of the highest probability result\n",
        "    index = np.argmax(results)\n",
        "    # Get the corresponding intent tag\n",
        "    tag = classes[index]\n",
        "\n",
        "    # If the probability of the predicted intent is below a certain threshold, return a default response\n",
        "    if results[index] < 0.5:\n",
        "        return \"I'm sorry, I don't understand. Can you please rephrase?\"\n",
        "\n",
        "    print(tag)\n",
        "    # Get a random response from the intent\n",
        "    for intent in intents:\n",
        "        if intent['tag'] == tag:\n",
        "            response = random.choice(intent['responses'])\n",
        "\n",
        "    return response\n",
        "\n",
        "# Main loop to get user input and generate responses\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() == \"quit\":\n",
        "            break\n",
        "    response = get_response(user_input)\n",
        "    print(\"CVA ::\", response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvJI24YheKDE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5uU9xqXeAkG",
        "outputId": "0fc132aa-d845-46d5-a5da-9d6309d5c3d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.1.1\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "print(keras.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ipvMSTX3muGP"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WPeUlpvuT6Mb"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "Can't pickle local object 'Layer._initializer_tracker.<locals>.<lambda>'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlemmatizer\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mAttributeError\u001b[0m: Can't pickle local object 'Layer._initializer_tracker.<locals>.<lambda>'"
          ]
        }
      ],
      "source": [
        "pickle.dump((model,lemmatizer , tokenizer,), open('model.pkl', 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYQG_tp8VmO3"
      },
      "outputs": [],
      "source": [
        "pickled_model,pickle_lemmatizer,pickle_tokenizer = pickle.load(open('model.pkl', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2L9CSbqVuP9",
        "outputId": "7b0bcfc0-af48-4211-e639-62b70444f376"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You: hi\n",
            "greeting\n",
            "CVA :: Hi there! What can I do for you?\n",
            "You: how are you\n",
            "situation\n",
            "CVA :: I'am fine,what about you?\n",
            "You: I am also good\n",
            "greetreply\n",
            "CVA :: Good to know!\n",
            "You: return order\n",
            "CVA :: I'm sorry, I don't understand. Can you please rephrase?\n",
            "You: return my order\n",
            "cancel_order\n",
            "CVA :: Sure, we can cancel your order. Please provide your order number and we will process the cancellation for you.\n",
            "You: order number is 123\n",
            "order_status\n",
            "CVA :: Our records show that your order is currently in transit. Please provide your order number if you need more information.\n",
            "You: what are payments method\n",
            "situation\n",
            "CVA :: I'am fine,what about you?\n",
            "You: what are payments method?\n",
            "payment_methods\n",
            "CVA :: Yes, we accept PayPal as a payment method.\n",
            "You: what is the payment process?\n",
            "payment_process\n",
            "CVA :: Sure, Once you have added the product to your cart, you can proceed to the checkout page. On the checkout page, you will see the payment options. Please select the payment option that suits you the best and add your credentials, and then follow the instructions to complete the payment.\n",
            "You: quit\n"
          ]
        }
      ],
      "source": [
        "# Define a function to process user input and generate a response\n",
        "def get_response(user_input):\n",
        "    # Tokenize and lemmatize the user input\n",
        "    words_in_input = pickle_tokenizer(user_input.lower())\n",
        "    words_in_input = [pickle_lemmatizer.lemmatize(word) for word in words_in_input]\n",
        "\n",
        "    # Create a bag of words for the user input\n",
        "    bag = [0] * len(words)\n",
        "    for word in words_in_input:\n",
        "        for i, w in enumerate(words):\n",
        "            if w == word:\n",
        "                bag[i] = 1\n",
        "\n",
        "    # Predict the intent of the user input using the trained model\n",
        "    results = pickled_model.predict(np.array([bag]), verbose=0)[0]\n",
        "    # Get the index of the highest probability result\n",
        "    index = np.argmax(results)\n",
        "    # Get the corresponding intent tag\n",
        "    tag = classes[index]\n",
        "\n",
        "    # If the probability of the predicted intent is below a certain threshold, return a default response\n",
        "    if results[index] < 0.5:\n",
        "        return \"I'm sorry, I don't understand. Can you please rephrase?\"\n",
        "\n",
        "    print(tag)\n",
        "    # Get a random response from the intent\n",
        "    for intent in intents:\n",
        "        if intent['tag'] == tag:\n",
        "            response = random.choice(intent['responses'])\n",
        "\n",
        "    return response\n",
        "\n",
        "# Main loop to get user input and generate responses\n",
        "while True:\n",
        "    user_input = input(\"You :: \")\n",
        "    if user_input.lower() == \"quit\":\n",
        "            break\n",
        "    response = get_response(user_input)\n",
        "    print(\"CVA :: \", response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g24zmEIWlCKu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the Parquet file\n",
        "df = pd.read_parquet('/content/train-00000-of-00001-a5a7c6e4bb30b016.parquet')\n",
        "\n",
        "# Save as CSV\n",
        "df.to_csv('cva_train_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1RePpfKnDgb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 981
        },
        "id": "GEFDc05J0zog",
        "outputId": "4a70ee3b-1beb-4fe4-f520-ed185f123ffc"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"issue_area\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Login and Account\",\n          \"Cancellations and returns\",\n          \"Shipping\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"issue_category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 40,\n        \"samples\": [\n          \"Warranty Terms and Changes\",\n          \"Accessing Warranty Details\",\n          \"Miscellaneous\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"issue_sub_category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 109,\n        \"samples\": [\n          \"Different order statuses in 'My Orders'\",\n          \"Time taken to cancel an order\",\n          \"Delivery not attempted again\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"issue_category_sub_category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 109,\n        \"samples\": [\n          \"Order Confirmation and Status -> Different order statuses in 'My Orders'\",\n          \"Order Cancellation -> Time taken to cancel an order\",\n          \"Order Delivery Issues -> Delivery not attempted again\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"customer_sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"negative\",\n          \"positive\",\n          \"neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"product_category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Appliances\",\n          \"Electronics\",\n          \"Men/Women/Kids\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"product_sub_category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 50,\n        \"samples\": [\n          \"Sandwich Maker\",\n          \"Electric Kettle\",\n          \"Pendrive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"issue_complexity\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"medium\",\n          \"less\",\n          \"high\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"agent_experience_level\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"junior\",\n          \"experienced\",\n          \"inexperienced\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"agent_experience_level_desc\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"handles customer inquiries independently, possess solid troubleshooting skills, and seek guidance from more experienced team members when needed.\",\n          \"confidently handles complex customer issues, excel in de-escalation, and possess the ability to empathize with customers, providing them with effective solutions and support.\",\n          \"may struggle with ambiguous queries, rely on clarification from customers or guidance from senior team members, find it difficult to de-escalate tense situations, and may rely on predefined steps or escalate to supervisors for support\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"conversation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 998,\n        \"samples\": [\n          \"Agent: Thank you for calling BrownBox Customer Support. My name is Jane. How may I assist you today?\\n\\nCustomer: Hi Jane, this is Emily. I have a question regarding the status of an order I placed on your website.\\n\\nAgent: Sure, Emily. I'd be happy to help you with that. Can you please provide me with your order number or email address associated with the purchase?\\n\\nCustomer: Yes, my order number is BB123456789.\\n\\nAgent: Thank you, Emily. Let me check the status of your order. \\n\\n[Agent puts the customer on hold briefly to investigate the issue]\\n\\nAgent: Thank you for waiting, Emily. I see that you ordered an electric cooker, and it is currently being processed for shipment. You should receive a confirmation email with the tracking details as soon as it is dispatched.\\n\\nCustomer: That's great to hear, Jane. I was just a little worried because I hadn't received any updates yet.\\n\\nAgent: I completely understand, Emily. Sometimes, there can be a delay in the confirmation email due to high order volumes. However, I can assure you that your order is being processed and will be shipped soon.\\n\\nCustomer: Thank you for checking that for me, Jane. I appreciate your help.\\n\\nAgent: You're welcome, Emily. Is there anything else I can assist you with?\\n\\nCustomer: No, that's all. Thank you for your help.\\n\\nAgent: My pleasure, Emily. If you have any other questions or concerns in the future, feel free to reach out to us. We value your business and strive to provide the best customer experience.\\n\\nCustomer: Thank you, Jane. Have a great day!\\n\\nAgent: Thank you, Emily. You too!\",\n          \"Agent: Hello, thank you for calling BrownBox customer support. My name is Tom. How may I assist you today?\\n\\nCustomer: Hi Tom, I have a complaint about my recent purchase. I ordered a refrigerator from your website, but it was delivered in parts by different sellers, and I'm facing difficulty in assembling it.\\n\\nAgent: I'm sorry to hear that. May I have your order number, please?\\n\\nCustomer: Yes, it's BB987654321.\\n\\nAgent: Thank you for providing that information. Let me check your order details. Could you please hold for a moment?\\n\\nCustomer: Okay, I'll hold.\\n\\nAgent: Thank you for waiting. I'm sorry for the inconvenience caused. I understand that you are facing difficulty in assembling the refrigerator. Is that correct?\\n\\nCustomer: Yes, that's right. I received the parts from different sellers, and I'm not sure how to assemble them.\\n\\nAgent: I see. We do offer clubbing orders from different sellers for combined delivery to save shipping costs. However, I understand that it may cause inconvenience to customers. Let me check if we can arrange for an expert to assist you in assembling the refrigerator. Could you please hold for a moment while I check?\\n\\nCustomer: Okay, I'll hold.\\n\\nAgent: Thank you for waiting. Unfortunately, we don't have an expert available for assembling the refrigerator. However, I can assist you in troubleshooting the issue. Do you have the user manual with you?\\n\\nCustomer: Yes, I do.\\n\\nAgent: Great. Please refer to the user manual and let me know which part you are facing difficulty in assembling.\\n\\nCustomer: It's the freezer compartment.\\n\\nAgent: Okay. Let me check the user manual. Could you please hold for a moment?\\n\\nCustomer: Okay, I'll hold.\\n\\nAgent: Thank you for waiting. I see that the user manual has detailed instructions on how to assemble the freezer compartment. It also has diagrams to help you understand the process. Would you like me to guide you through the process?\\n\\nCustomer: Yes, please.\\n\\nAgent: Okay. First, you need to attach the rails to the freezer compartment door. Then, you need to slide the freezer compartment onto the rails. Once it's in place, you need to secure it with screws. Do you have a screwdriver with you?\\n\\nCustomer: Yes, I do.\\n\\nAgent: Great. Please follow the instructions in the user manual, and let me know if you face any difficulty.\\n\\nCustomer: Okay, I'll try.\\n\\nAgent: Sure. If you face any difficulty, please don't hesitate to contact us. We are here to assist you. Is there anything else I can help you with?\\n\\nCustomer: No, that's all. Thank you for your help.\\n\\nAgent: You're welcome. If you have any further questions or concerns, please feel free to contact us. Have a great day!\\n\\nCustomer: Thanks, you too. Goodbye!\\n\\nAgent: Goodbye!\",\n          \"Agent: Thank you for calling BrownBox Customer Support. My name is Sarah. How may I assist you today?\\n\\nCustomer: Hi, Sarah. I was browsing your website and noticed that the sweatshirt I want to purchase has different prices. Can you explain why?\\n\\nAgent: I'm sorry to hear that, and I'll be happy to assist you. May I know the name of the sweatshirt you are interested in?\\n\\nCustomer: Yes, it's the Grey Hooded Sweatshirt.\\n\\nAgent: Thank you, and can you please tell me where you saw different prices for the sweatshirt?\\n\\nCustomer: Yes, I saw different prices on the product page and the checkout page.\\n\\nAgent: I see. That might be due to a glitch in our system. Can you please tell me the prices you saw on both pages?\\n\\nCustomer: Sure, on the product page, the price was $29.99, and on the checkout page, the price was $39.99.\\n\\nAgent: Thank you for letting me know. I think I know what's going on here. The $29.99 price is the regular price, and the $39.99 price is the sale price. However, it looks like the sale price did not apply to your purchase.\\n\\nCustomer: But I saw the sale price on the checkout page. Why didn't it apply to my purchase?\\n\\nAgent: I'm sorry for the confusion. It's possible that the sale price did not apply to your purchase because the sweatshirt might not be eligible for the sale price. May I ask if you have added any other items to your cart?\\n\\nCustomer: No, I only added the Grey Hooded Sweatshirt to my cart.\\n\\nAgent: I see. In that case, it might be best if I transfer you to one of our senior team members who can assist you further with this issue. Would that be okay with you?\\n\\nCustomer: Yes, please. That would be great.\\n\\nAgent: Okay, please hold the line while I transfer you to our senior team member.\\n\\n(Sarah transfers the call to a senior team member)\\n\\nSenior Team Member: Hello, this is Mike. How may I assist you today?\\n\\nCustomer: Hi, Mike. I was browsing your website and noticed that the sweatshirt I want to purchase has different prices. Can you explain why?\\n\\nSenior Team Member: I'm sorry to hear that, and I'll be happy to assist you. Can you please tell me the name of the sweatshirt you are interested in?\\n\\nCustomer: Yes, it's the Grey Hooded Sweatshirt.\\n\\nSenior Team Member: Thank you, and can you please tell me where you saw different prices for the sweatshirt?\\n\\nCustomer: Yes, I saw different prices on the product page and the checkout page.\\n\\nSenior Team Member: I see. That might be due to a glitch in our system. However, I can confirm that the regular price for the Grey Hooded Sweatshirt is $29.99, and the sale price is $39.99. The sale price applies to eligible items only, and it looks like the sweatshirt you want to purchase is not eligible for the sale price.\\n\\nCustomer: Oh, I see. Thank you for clarifying that.\\n\\nSenior Team Member: You're welcome. Is there anything else I can assist you with?\\n\\nCustomer: No, that's all for now. Thank you for your help, Mike.\\n\\nSenior Team Member: You're welcome. If you have any further questions or concerns, don't hesitate to reach out. Thank you for choosing BrownBox, and have a great day!\\n\\nCustomer: Thank you. You too. Goodbye!\\n\\nSenior Team Member: Goodbye!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-5f1f2e5f-6aa6-40bd-aa2c-2c6b675e20d9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>issue_area</th>\n",
              "      <th>issue_category</th>\n",
              "      <th>issue_sub_category</th>\n",
              "      <th>issue_category_sub_category</th>\n",
              "      <th>customer_sentiment</th>\n",
              "      <th>product_category</th>\n",
              "      <th>product_sub_category</th>\n",
              "      <th>issue_complexity</th>\n",
              "      <th>agent_experience_level</th>\n",
              "      <th>agent_experience_level_desc</th>\n",
              "      <th>conversation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Login and Account</td>\n",
              "      <td>Mobile Number and Email Verification</td>\n",
              "      <td>Verification requirement for mobile number or ...</td>\n",
              "      <td>Mobile Number and Email Verification -&gt; Verifi...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Appliances</td>\n",
              "      <td>Oven Toaster Grills (OTG)</td>\n",
              "      <td>medium</td>\n",
              "      <td>junior</td>\n",
              "      <td>handles customer inquiries independently, poss...</td>\n",
              "      <td>Agent: Thank you for calling BrownBox Customer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Cancellations and returns</td>\n",
              "      <td>Pickup and Shipping</td>\n",
              "      <td>Reasons for being asked to ship the item</td>\n",
              "      <td>Pickup and Shipping -&gt; Reasons for being asked...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Electronics</td>\n",
              "      <td>Computer Monitor</td>\n",
              "      <td>less</td>\n",
              "      <td>junior</td>\n",
              "      <td>handles customer inquiries independently, poss...</td>\n",
              "      <td>Agent: Thank you for calling BrownBox customer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Cancellations and returns</td>\n",
              "      <td>Replacement and Return Process</td>\n",
              "      <td>Inability to click the 'Cancel' button</td>\n",
              "      <td>Replacement and Return Process -&gt; Inability to...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Appliances</td>\n",
              "      <td>Juicer/Mixer/Grinder</td>\n",
              "      <td>medium</td>\n",
              "      <td>experienced</td>\n",
              "      <td>confidently handles complex customer issues, e...</td>\n",
              "      <td>Agent: Thank you for calling BrownBox Customer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Login and Account</td>\n",
              "      <td>Login Issues and Error Messages</td>\n",
              "      <td>Error message regarding exceeded attempts to e...</td>\n",
              "      <td>Login Issues and Error Messages -&gt; Error messa...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Appliances</td>\n",
              "      <td>Water Purifier</td>\n",
              "      <td>less</td>\n",
              "      <td>inexperienced</td>\n",
              "      <td>may struggle with ambiguous queries, rely on c...</td>\n",
              "      <td>Customer: Hi, I am facing an issue while loggi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Order</td>\n",
              "      <td>Order Delivery Issues</td>\n",
              "      <td>Delivery not attempted again</td>\n",
              "      <td>Order Delivery Issues -&gt; Delivery not attempte...</td>\n",
              "      <td>negative</td>\n",
              "      <td>Electronics</td>\n",
              "      <td>Bp Monitor</td>\n",
              "      <td>medium</td>\n",
              "      <td>experienced</td>\n",
              "      <td>confidently handles complex customer issues, e...</td>\n",
              "      <td>Agent: Thank you for contacting BrownBox custo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>Cancellations and returns</td>\n",
              "      <td>Return and Exchange</td>\n",
              "      <td>Package open or tampered on delivery</td>\n",
              "      <td>Return and Exchange -&gt; Package open or tampere...</td>\n",
              "      <td>negative</td>\n",
              "      <td>Electronics</td>\n",
              "      <td>Mobile</td>\n",
              "      <td>medium</td>\n",
              "      <td>junior</td>\n",
              "      <td>handles customer inquiries independently, poss...</td>\n",
              "      <td>Agent: Thank you for calling BrownBox Customer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>Cancellations and returns</td>\n",
              "      <td>Pickup and Shipping</td>\n",
              "      <td>Reasons for being asked to ship the item</td>\n",
              "      <td>Pickup and Shipping -&gt; Reasons for being asked...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Men/Women/Kids</td>\n",
              "      <td>Backpack</td>\n",
              "      <td>medium</td>\n",
              "      <td>junior</td>\n",
              "      <td>handles customer inquiries independently, poss...</td>\n",
              "      <td>Customer: Hi, I received an email from BrownBo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>Warranty</td>\n",
              "      <td>Warranty Terms and Changes</td>\n",
              "      <td>Warranty mismatch between the website and the ...</td>\n",
              "      <td>Warranty Terms and Changes -&gt; Warranty mismatc...</td>\n",
              "      <td>negative</td>\n",
              "      <td>Appliances</td>\n",
              "      <td>Water Purifier</td>\n",
              "      <td>less</td>\n",
              "      <td>junior</td>\n",
              "      <td>handles customer inquiries independently, poss...</td>\n",
              "      <td>Agent: Thank you for calling BrownBox Customer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>Cancellations and returns</td>\n",
              "      <td>Return and Exchange</td>\n",
              "      <td>Checking the status of a refund</td>\n",
              "      <td>Return and Exchange -&gt; Checking the status of ...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Appliances</td>\n",
              "      <td>Wet Grinder</td>\n",
              "      <td>medium</td>\n",
              "      <td>junior</td>\n",
              "      <td>handles customer inquiries independently, poss...</td>\n",
              "      <td>Customer: Hi, I would like to check the status...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>Order</td>\n",
              "      <td>Order Delivery Issues</td>\n",
              "      <td>Package not delivered</td>\n",
              "      <td>Order Delivery Issues -&gt; Package not delivered</td>\n",
              "      <td>negative</td>\n",
              "      <td>Electronics</td>\n",
              "      <td>Mobile</td>\n",
              "      <td>less</td>\n",
              "      <td>junior</td>\n",
              "      <td>handles customer inquiries independently, poss...</td>\n",
              "      <td>Customer: Hi, I am calling because I have not ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 11 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f1f2e5f-6aa6-40bd-aa2c-2c6b675e20d9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5f1f2e5f-6aa6-40bd-aa2c-2c6b675e20d9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5f1f2e5f-6aa6-40bd-aa2c-2c6b675e20d9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-71cfd909-6d34-4773-a5fa-57546ec42baf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-71cfd909-6d34-4773-a5fa-57546ec42baf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-71cfd909-6d34-4773-a5fa-57546ec42baf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_bee9fbc3-ce29-4e47-bbd8-de25e9b9bd7e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_bee9fbc3-ce29-4e47-bbd8-de25e9b9bd7e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                    issue_area                        issue_category  \\\n",
              "0            Login and Account  Mobile Number and Email Verification   \n",
              "1    Cancellations and returns                   Pickup and Shipping   \n",
              "2    Cancellations and returns        Replacement and Return Process   \n",
              "3            Login and Account       Login Issues and Error Messages   \n",
              "4                        Order                 Order Delivery Issues   \n",
              "..                         ...                                   ...   \n",
              "995  Cancellations and returns                   Return and Exchange   \n",
              "996  Cancellations and returns                   Pickup and Shipping   \n",
              "997                   Warranty            Warranty Terms and Changes   \n",
              "998  Cancellations and returns                   Return and Exchange   \n",
              "999                      Order                 Order Delivery Issues   \n",
              "\n",
              "                                    issue_sub_category  \\\n",
              "0    Verification requirement for mobile number or ...   \n",
              "1             Reasons for being asked to ship the item   \n",
              "2               Inability to click the 'Cancel' button   \n",
              "3    Error message regarding exceeded attempts to e...   \n",
              "4                         Delivery not attempted again   \n",
              "..                                                 ...   \n",
              "995               Package open or tampered on delivery   \n",
              "996           Reasons for being asked to ship the item   \n",
              "997  Warranty mismatch between the website and the ...   \n",
              "998                    Checking the status of a refund   \n",
              "999                              Package not delivered   \n",
              "\n",
              "                           issue_category_sub_category customer_sentiment  \\\n",
              "0    Mobile Number and Email Verification -> Verifi...            neutral   \n",
              "1    Pickup and Shipping -> Reasons for being asked...            neutral   \n",
              "2    Replacement and Return Process -> Inability to...            neutral   \n",
              "3    Login Issues and Error Messages -> Error messa...            neutral   \n",
              "4    Order Delivery Issues -> Delivery not attempte...           negative   \n",
              "..                                                 ...                ...   \n",
              "995  Return and Exchange -> Package open or tampere...           negative   \n",
              "996  Pickup and Shipping -> Reasons for being asked...            neutral   \n",
              "997  Warranty Terms and Changes -> Warranty mismatc...           negative   \n",
              "998  Return and Exchange -> Checking the status of ...            neutral   \n",
              "999     Order Delivery Issues -> Package not delivered           negative   \n",
              "\n",
              "    product_category       product_sub_category issue_complexity  \\\n",
              "0         Appliances  Oven Toaster Grills (OTG)           medium   \n",
              "1        Electronics           Computer Monitor             less   \n",
              "2         Appliances       Juicer/Mixer/Grinder           medium   \n",
              "3         Appliances             Water Purifier             less   \n",
              "4        Electronics                 Bp Monitor           medium   \n",
              "..               ...                        ...              ...   \n",
              "995      Electronics                     Mobile           medium   \n",
              "996   Men/Women/Kids                   Backpack           medium   \n",
              "997       Appliances             Water Purifier             less   \n",
              "998       Appliances                Wet Grinder           medium   \n",
              "999      Electronics                     Mobile             less   \n",
              "\n",
              "    agent_experience_level                        agent_experience_level_desc  \\\n",
              "0                   junior  handles customer inquiries independently, poss...   \n",
              "1                   junior  handles customer inquiries independently, poss...   \n",
              "2              experienced  confidently handles complex customer issues, e...   \n",
              "3            inexperienced  may struggle with ambiguous queries, rely on c...   \n",
              "4              experienced  confidently handles complex customer issues, e...   \n",
              "..                     ...                                                ...   \n",
              "995                 junior  handles customer inquiries independently, poss...   \n",
              "996                 junior  handles customer inquiries independently, poss...   \n",
              "997                 junior  handles customer inquiries independently, poss...   \n",
              "998                 junior  handles customer inquiries independently, poss...   \n",
              "999                 junior  handles customer inquiries independently, poss...   \n",
              "\n",
              "                                          conversation  \n",
              "0    Agent: Thank you for calling BrownBox Customer...  \n",
              "1    Agent: Thank you for calling BrownBox customer...  \n",
              "2    Agent: Thank you for calling BrownBox Customer...  \n",
              "3    Customer: Hi, I am facing an issue while loggi...  \n",
              "4    Agent: Thank you for contacting BrownBox custo...  \n",
              "..                                                 ...  \n",
              "995  Agent: Thank you for calling BrownBox Customer...  \n",
              "996  Customer: Hi, I received an email from BrownBo...  \n",
              "997  Agent: Thank you for calling BrownBox Customer...  \n",
              "998  Customer: Hi, I would like to check the status...  \n",
              "999  Customer: Hi, I am calling because I have not ...  \n",
              "\n",
              "[1000 rows x 11 columns]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"/content/cva_train_data.csv\")\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-02DDPYv03r5"
      },
      "outputs": [],
      "source": [
        "# Initialize the lemmatizer and tokenizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "tokenizer = word_tokenize\n",
        "# Create a list of all words in the intents, and a list of all intents\n",
        "words = []\n",
        "classes = []\n",
        "documents = []\n",
        "for intent in intents:\n",
        "    for pattern in df['issue_category_sub_category']:\n",
        "        # Tokenize and lemmatize each word in the pattern\n",
        "        words_in_pattern = tokenizer(pattern.lower())\n",
        "        words_in_pattern = [lemmatizer.lemmatize(word) for word in words_in_pattern]\n",
        "        # Add the words to the list of all words\n",
        "        words.extend(words_in_pattern)\n",
        "        # Add the pattern and intent to the list of all documents\n",
        "        documents.append((words_in_pattern, df['issue_area']))\n",
        "        # Add the intent to the list of all intents\n",
        "        if df['issue_area'] not in classes:\n",
        "            classes.append(df['issue_area'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvCczU4V1nX4"
      },
      "outputs": [],
      "source": [
        "# Remove duplicates and sort the words and classes\n",
        "words = sorted(list(set(words)))\n",
        "classes = sorted(classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Sd7GARt1y-L"
      },
      "outputs": [],
      "source": [
        "# Create training data as a bag of words\n",
        "training_data = []\n",
        "for document in documents:\n",
        "    bag = []\n",
        "    # Create a bag of words for each document\n",
        "    for word in words:\n",
        "        bag.append(1) if word in document[0] else bag.append(0)\n",
        "    # Append the bag of words and the intent tag to the training data\n",
        "    output_row = [0] * len(classes)\n",
        "    output_row[classes.index(document[1])] = 1\n",
        "    training_data.append([bag, output_row])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZja9tPE2Ga3"
      },
      "outputs": [],
      "source": [
        "# Shuffle the training data and split it into input and output lists\n",
        "random.shuffle(training_data)\n",
        "training_data = np.array(training_data, dtype=object)\n",
        "train_x = list(training_data[:, 0])\n",
        "train_y = list(training_data[:, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBlBMKro2gRM"
      },
      "outputs": [],
      "source": [
        "# Define the neural network model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, input_shape=(len(train_x[0]),), activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(len(train_y[0]), activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xd3Q3VHs2t6L",
        "outputId": "e1123bdb-d219-4ce8-af27-09bc528669b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(5, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7400/7400 [==============================] - 26s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 2/5\n",
            "7400/7400 [==============================] - 23s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "7400/7400 [==============================] - 23s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "7400/7400 [==============================] - 23s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "7400/7400 [==============================] - 23s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c6f682428f0>"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(np.array(train_x), np.array(train_y), epochs=5, batch_size=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "B7ZMjP_922DQ",
        "outputId": "e07b0b9d-eee3-43e9-a0d0-4aeeea81cde1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You: hello\n",
            "tags ::  Cancellations and returns\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "string indices must be integers",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-12c8d09474e9>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"quit\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CVA ::\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-12c8d09474e9>\u001b[0m in \u001b[0;36mget_response\u001b[0;34m(user_input)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Get a random response from the intent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mintent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mintent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'issue_category_sub_category'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'responses'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
          ]
        }
      ],
      "source": [
        "# Define a function to process user input and generate a response\n",
        "def get_response(user_input):\n",
        "    # Tokenize and lemmatize the user input\n",
        "    words_in_input = tokenizer(user_input.lower())\n",
        "    words_in_input = [lemmatizer.lemmatize(word) for word in words_in_input]\n",
        "\n",
        "    # Create a bag of words for the user input\n",
        "    bag = [0] * len(words)\n",
        "    for word in words_in_input:\n",
        "        for i, w in enumerate(words):\n",
        "            if w == word:\n",
        "                bag[i] = 1\n",
        "\n",
        "    # Predict the intent of the user input using the trained model\n",
        "    results = model.predict(np.array([bag]), verbose=0)[0]\n",
        "    # Get the index of the highest probability result\n",
        "    index = np.argmax(results)\n",
        "    # Get the corresponding intent tag\n",
        "    tag = classes[index]\n",
        "\n",
        "    # If the probability of the predicted intent is below a certain threshold, return a default response\n",
        "    if results[index] < 0.5:\n",
        "        return \"I'm sorry, I don't understand. Can you please rephrase?\"\n",
        "    print(\"tags :: \",tag[1])\n",
        "    # Get a random response from the intent\n",
        "    for intent in df:\n",
        "        if intent['issue_category_sub_category'] == tag[1]:\n",
        "            response = random.choice(intent['responses'])\n",
        "\n",
        "    return response\n",
        "\n",
        "# Main loop to get user input and generate responses\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() == \"quit\":\n",
        "            break\n",
        "    response = get_response(user_input)\n",
        "    print(\"CVA ::\", response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_-Or6BR8EDb",
        "outputId": "ee579c93-3f9c-478e-98cc-799b3b9925c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'tag': 'greeting',\n",
              "  'patterns': ['Hi', 'Hey', 'Is anyone there?', 'Hello', 'Hay'],\n",
              "  'responses': ['Hello! How can I help you today?',\n",
              "   'Hi there! What can I do for you?',\n",
              "   'Hey! What do you need help with?']},\n",
              " {'tag': 'goodbye',\n",
              "  'patterns': ['Bye', 'See you later', 'Goodbye'],\n",
              "  'responses': ['See you later', 'Have a nice day', 'Bye! Come back again']},\n",
              " {'tag': 'thanks',\n",
              "  'patterns': ['Thanks',\n",
              "   'Thank you',\n",
              "   \"That's helpful\",\n",
              "   'Thanks for the help',\n",
              "   'ok thanks'],\n",
              "  'responses': [\"You're welcome, sir. If you have any other questions or concerns, feel free to reach out. Have a great day!\",\n",
              "   'Happy to help!',\n",
              "   'Any time!',\n",
              "   'My pleasure',\n",
              "   \"You're most welcome!\"]},\n",
              " {'tag': 'about',\n",
              "  'patterns': ['Who are you?', 'What are you?', 'Who you are?'],\n",
              "  'responses': ['I am Shifra, your bot assistant',\n",
              "   \"I'm Shifra, an Artificial Intelligent bot\"]},\n",
              " {'tag': 'name',\n",
              "  'patterns': ['what is your name',\n",
              "   'what should I call you',\n",
              "   'whats your name?'],\n",
              "  'responses': ['You can call me Shifra.',\n",
              "   \"I'm Shifra!\",\n",
              "   'Just call me as Shifra']},\n",
              " {'tag': 'my_name',\n",
              "  'patterns': ['My name is {{name}}', 'I am {{name}}', \"I'm {{name}}\"],\n",
              "  'responses': ['Hello {{name}}, I am Shifra.',\n",
              "   \"Hii I'm Shifra!, How can I help you\",\n",
              "   'Hello {{name}}, How you doing?']},\n",
              " {'tag': 'help',\n",
              "  'patterns': ['Could you help me?',\n",
              "   'give me a hand please',\n",
              "   'Can you help?',\n",
              "   'What can you do for me?',\n",
              "   'I need a support',\n",
              "   'I need a help',\n",
              "   'support me please'],\n",
              "  'responses': ['Tell me how can I assist you',\n",
              "   'Tell me your problem to assist you',\n",
              "   'Yes Sure, How can I support you']},\n",
              " {'tag': 'account',\n",
              "  'patterns': ['Sure, my email address is johnsmith@email.com, and my phone number is 123-456-7890.'],\n",
              "  'responses': ['Thank you for verifying your account details, John. Let me check your account information.',\n",
              "   'It looks like your account has been inactive for more than six months, which is why it has been deactivated.']},\n",
              " {'tag': 'identity',\n",
              "  'patterns': ['My name is John Smith, my billing address is 123 Main Street, Anytown, USA, and the last four digits of my credit card are 1234.'],\n",
              "  'responses': ['Thank you for verifying your identity, John. I have reactivated your account, and you should be able to log in now. Can you please try logging in and let me know if you face any issues?']},\n",
              " {'tag': 'reactivate_account',\n",
              "  'patterns': [\"'m trying to reactivate my account to purchase a Wet Grinder, but it's not letting me log in.\"],\n",
              "  'responses': [\"I'm sorry to hear that. May I have your email address and phone number associated with the account, please?\"]},\n",
              " {'tag': 'createaccount',\n",
              "  'patterns': ['I need to create a new account',\n",
              "   'how to open a new account',\n",
              "   'I want to create an account',\n",
              "   'can you create an account for me',\n",
              "   'how to open a new account'],\n",
              "  'responses': ['You can just easily create a new account from our web site',\n",
              "   'Just go to our web site and follow the guidelines to create a new account']},\n",
              " {'tag': 'complaint',\n",
              "  'patterns': ['i have a complaint',\n",
              "   'I want to raise a complaint',\n",
              "   'there is a complaint about a service'],\n",
              "  'responses': ['Please provide us your complaint in order to assist you',\n",
              "   'Please mention your complaint, we will reach you and sorry for any inconvenience caused']},\n",
              " {'tag': 'situation',\n",
              "  'patterns': ['how are you',\n",
              "   'how was your day',\n",
              "   'talk me about your day',\n",
              "   \"what's up\"],\n",
              "  'responses': [\"I'am fine,what about you?\",\n",
              "   'I am doing well,do you?',\n",
              "   'I am feeling good,wbu?',\n",
              "   'I am good,wbu?']},\n",
              " {'tag': 'noanswer',\n",
              "  'patterns': [''],\n",
              "  'responses': [\"Sorry, can't understand you\",\n",
              "   'Please give me more info',\n",
              "   'Not sure I understand']},\n",
              " {'tag': 'exclaim',\n",
              "  'patterns': ['Awesome', 'Great', 'I know', 'ok', 'yeah'],\n",
              "  'responses': ['Yeah!']},\n",
              " {'tag': 'password',\n",
              "  'patterns': [\"I can't remember my password\",\n",
              "   'I forget my password',\n",
              "   \"i can't access my account with my password\",\n",
              "   \"i can't log in\",\n",
              "   'my password is invalid'],\n",
              "  'responses': ['okay you need to reset your password,follow my steps click on forget password below the page then enter your email and we will send a activition code so you can reset your password']},\n",
              " {'tag': 'service',\n",
              "  'patterns': [\"I'm really frustrated with the service.\",\n",
              "   'my account service is no working',\n",
              "   'Page Service is not responding',\n",
              "   'There is a bug in the system'],\n",
              "  'responses': [\"I'm sorry to hear that, sir. I understand how frustrating it can be,tell me how can I help you\",\n",
              "   'okay you need to make a report to our technical team',\n",
              "   'i guess you should contact with our technical team']},\n",
              " {'tag': 'email',\n",
              "  'patterns': [\"i can't remember my email\",\n",
              "   \"i can't get my email\",\n",
              "   'my email is invalid',\n",
              "   'i forget my email',\n",
              "   \"i can't access my accound with my email\"],\n",
              "  'responses': [\"click on forget email or password below the page and press on can't remember my email we will ask you to enter your phone number so we can send you an activition code to recover your account\"]},\n",
              " {'tag': 'billing',\n",
              "  'patterns': [\"my payment didn't go through\",\n",
              "   'My payment was not accepted',\n",
              "   'My payment was unsuccessful'],\n",
              "  'responses': ['i will see it in my pending payment',\n",
              "   \"I'll check my pending payment\",\n",
              "   \"I'll check my balance due\"]},\n",
              " {'tag': 'delivery',\n",
              "  'patterns': [\"my package didn't arrive\",\n",
              "   \"I'm not able to track my order.\",\n",
              "   'My package never come',\n",
              "   'My shipment never came'],\n",
              "  'responses': ['i will check my job scheduling',\n",
              "   \"I'm sorry to hear that, sir. I understand how frustrating it can be when you don't receive your order on time. Could you please provide me with the order number and your current address?\",\n",
              "   \"I'll double-check my work schedule\"]},\n",
              " {'tag': 'order_status',\n",
              "  'patterns': ['Where is my order?',\n",
              "   'What is the status of my order?',\n",
              "   'When will my order arrive?'],\n",
              "  'responses': ['Please provide your order number and we will check the status for you.',\n",
              "   'We apologize for any delay. Please provide your order number and we will look into it.',\n",
              "   'Our records show that your order is currently in transit. Please provide your order number if you need more information.']},\n",
              " {'tag': 'cancel_order',\n",
              "  'patterns': ['Can I cancel my order?',\n",
              "   'I want to cancel my order',\n",
              "   'How do I cancel my order?',\n",
              "   'I have an issue with my order'],\n",
              "  'responses': ['Sure, we can cancel your order. Please provide your order number and we will process the cancellation for you.',\n",
              "   'We apologize for any inconvenience. Please provide your order number and we will cancel your order for you.',\n",
              "   'Of course, we can cancel your order. Please provide your order number and we will take care of it.']},\n",
              " {'tag': 'return_policy',\n",
              "  'patterns': ['What is your return policy?',\n",
              "   'How do I return an item?',\n",
              "   'Can I get a refund?'],\n",
              "  'responses': ['Our return policy allows for returns within 30 days of purchase. Please visit our website for more information.',\n",
              "   'To return an item, please visit our website and follow the instructions on our returns page.',\n",
              "   'If you are not satisfied with your purchase, we offer refunds within 30 days of purchase. Please visit our website for more information.']},\n",
              " {'tag': 'payment_methods',\n",
              "  'patterns': ['What payment methods do you accept?',\n",
              "   'Can I pay with PayPal?',\n",
              "   'Do you accept credit cards?'],\n",
              "  'responses': ['We accept all major credit cards, as well as PayPal and Apple Pay.',\n",
              "   'Yes, we accept PayPal as a payment method.',\n",
              "   'We accept all major credit cards, including Visa, Mastercard, and American Express.']},\n",
              " {'tag': 'shipping_options',\n",
              "  'patterns': ['What are my shipping options?',\n",
              "   'How much does shipping cost?',\n",
              "   'When will my order arrive?'],\n",
              "  'responses': ['We offer a variety of shipping options, including standard, expedited, and overnight shipping. Shipping costs vary depending on the shipping method and the destination.',\n",
              "   'Shipping costs vary depending on the shipping method and the destination. Please visit our website for more information.',\n",
              "   'Our standard shipping typically takes 3-5 business days to arrive, but shipping times may vary depending on the shipping method and the destination.']},\n",
              " {'tag': 'product_info',\n",
              "  'patterns': ['Can you tell me more about this product?',\n",
              "   'What are the specifications of this product?',\n",
              "   'What materials is this product made of?'],\n",
              "  'responses': ['Certainly! Our products are made of high-quality materials and are designed to last. Please visit our website for more information on this product.',\n",
              "   'This product is made of durable materials and is designed to meet our high standards of quality. Please visit our website for more information.',\n",
              "   'We use only the finest materials in our products, and this product is no exception. Please visit our website for more information on this product.']},\n",
              " {'tag': 'jokes',\n",
              "  'patterns': ['Tell me a joke', 'Joke', 'Make me laugh'],\n",
              "  'responses': [\"A perfectionist walked into a bar...apparently, the bar wasn't set high enough\",\n",
              "   'I ate a clock yesterday, it was very time-consuming',\n",
              "   \"Never criticize someone until you've walked a mile in their shoes. That way, when you criticize them, they won't be able to hear you from that far away. Plus, you'll have their shoes.\",\n",
              "   \"The world tongue-twister champion just got arrested. I hear they're gonna give him a really tough sentence.\",\n",
              "   \"I own the world's worst thesaurus. Not only is it awful, it's awful.\",\n",
              "   'What did the traffic light say to the car? \"Don\\'t look now, I\\'m changing.\"',\n",
              "   'What do you call a snowman with a suntan? A puddle.',\n",
              "   'How does a penguin build a house? Igloos it together',\n",
              "   'I went to see the doctor about my short-term memory problems – the first thing he did was make me pay in advance',\n",
              "   'As I get older and I remember all the people I’ve lost along the way, I think to myself, maybe a career as a tour guide wasn’t for me.',\n",
              "   \"o what if I don't know what 'Armageddon' means? It's not the end of the world.\"]},\n",
              " {'tag': 'haha',\n",
              "  'patterns': ['haha', 'lol', 'rofl', 'lmao', 'thats funny'],\n",
              "  'responses': ['Glad I could make you laugh !']},\n",
              " {'tag': 'programmer',\n",
              "  'patterns': ['Who made you', 'who designed you', 'who programmed you'],\n",
              "  'responses': ['I was made by Eissa Islam & Mariam Medhat & Farah Waleed.']},\n",
              " {'tag': 'insult',\n",
              "  'patterns': ['you are dumb', 'shut up', 'idiot'],\n",
              "  'responses': ['Well that hurts :(',\n",
              "   'It sad to know that I could not satisfy your needs']},\n",
              " {'tag': 'nicetty',\n",
              "  'patterns': ['it was nice talking to you', 'good talk'],\n",
              "  'responses': ['It was nice talking to you as well! Come back soon!']},\n",
              " {'tag': 'no', 'patterns': ['no', 'nope'], 'responses': ['ok']},\n",
              " {'tag': 'age',\n",
              "  'patterns': ['how old are you', 'when were you made', 'what is your age'],\n",
              "  'responses': [\"I was made in 2023, if that's what you are asking!\"]},\n",
              " {'tag': 'greetreply',\n",
              "  'patterns': ['i am good', \"I'm good\", 'i am fine', \" i'm fine\", 'good'],\n",
              "  'responses': ['Good to know!']},\n",
              " {'tag': 'query',\n",
              "  'patterns': [],\n",
              "  'responses': ['I apologize for the inconvenience caused.']},\n",
              " {'tag': 'return_order',\n",
              "  'patterns': ['I want to return it and get a refund.']},\n",
              " {'tag': 'oder_number',\n",
              "  'patterns': ['My order number is {{BB123456}}.'],\n",
              "  'responses': ['Thank you for providing the order number. Let me check the status of your order.',\n",
              "   ' Thank you for waiting, sir. I apologize for the inconvenience caused. I see that the delivery was not attempted again due to an issue with the address provided. However, I assure you that we will take the necessary steps to ensure that you receive your order as soon as possible.']}]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for i in intents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPRlBRSU8gAo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
